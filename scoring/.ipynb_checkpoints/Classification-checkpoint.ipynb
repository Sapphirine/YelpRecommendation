{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phtot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from data_processing.classification import load_data as load\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "path = \"/Users/mikezhao/Downloads/Bigdata/classification/5/\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "def resize():\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            Image.open(path+item).convert('RGB').save(path+item)\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((256,256), Image.ANTIALIAS)\n",
    "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
    "\n",
    "resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/mikezhao/Downloads/Bigdata/trainbad/\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "def resize():\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            Image.open(path+item).convert('RGB').save(path+item)\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((256,256), Image.ANTIALIAS)\n",
    "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
    "\n",
    "resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6586, 256, 256, 3)\n",
      "(6586,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load(mode='all')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "num_training = 6000\n",
    "num_validation = 586\n",
    "arr = np.arange(6586)\n",
    "np.random.shuffle(arr)\n",
    "X_val = X_train[arr[0:num_validation]]\n",
    "y_val = y_train[arr[0:num_validation]]\n",
    "X_train = X_train[arr[num_validation:]]\n",
    "y_train = y_train[arr[num_validation:]]\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[32, 64]\n",
      "fc_units=[84]\n",
      "conv_kernel_size=[5, 5]\n",
      "pooling_size=[2, 2]\n",
      "l2_norm=0.01\n",
      "seed=2\n",
      "learning_rate=0.01\n",
      "number of batches for training: 46\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:50 accuracy: 50.51194539249147%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:100 accuracy: 64.33447098976109%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:150 accuracy: 64.84641638225256%\n",
      "epoch 5 \n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:300 accuracy: 69.62457337883959%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:350 accuracy: 69.79522184300342%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:400 accuracy: 69.96587030716724%\n",
      "epoch 10 \n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:500 accuracy: 72.0136518771331%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "epoch 14 \n",
      "Best validation accuracy! iteration:600 accuracy: 74.06143344709898%\n",
      "epoch 15 \n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:800 accuracy: 75.93856655290102%\n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:850 accuracy: 76.10921501706486%\n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:900 accuracy: 76.79180887372013%\n",
      "epoch 21 \n",
      "epoch 22 \n",
      "Best validation accuracy! iteration:1000 accuracy: 77.9863481228669%\n",
      "epoch 23 \n",
      "epoch 24 \n",
      "epoch 25 \n",
      "epoch 26 \n",
      "epoch 27 \n",
      "epoch 28 \n",
      "Best validation accuracy! iteration:1250 accuracy: 78.66894197952219%\n",
      "epoch 29 \n",
      "epoch 30 \n",
      "Best validation accuracy! iteration:1350 accuracy: 78.839590443686%\n",
      "epoch 31 \n",
      "epoch 32 \n",
      "epoch 33 \n",
      "epoch 34 \n",
      "epoch 35 \n",
      "epoch 36 \n",
      "epoch 37 \n",
      "Best validation accuracy! iteration:1700 accuracy: 79.18088737201364%\n",
      "epoch 38 \n",
      "epoch 39 \n",
      "epoch 40 \n",
      "epoch 41 \n",
      "Best validation accuracy! iteration:1850 accuracy: 79.5221843003413%\n",
      "epoch 42 \n",
      "epoch 43 \n",
      "epoch 44 \n",
      "epoch 45 \n",
      "epoch 46 \n",
      "epoch 47 \n",
      "epoch 48 \n",
      "epoch 49 \n",
      "epoch 50 \n",
      "[  9.98891354e-01   9.27987576e-01   8.73989344e-01   6.97654366e-01\n",
      "   8.51194084e-01   9.67933178e-01   9.99927104e-01   9.97405350e-01\n",
      "   2.80377833e-04   8.97766724e-02   8.51900637e-01   5.43339908e-01\n",
      "   9.97880995e-01   4.14548479e-02   9.99809206e-01   5.46674609e-01\n",
      "   9.99955952e-01   9.98130977e-01   5.92833757e-01   9.99727428e-01\n",
      "   9.96806741e-01   9.99961436e-01   6.96848035e-01   2.61576060e-04\n",
      "   6.11735702e-01   8.12479854e-01   9.81616318e-01   4.15899121e-04\n",
      "   6.87276224e-06   3.91115900e-03   9.71560180e-01   3.31863314e-02\n",
      "   5.80844343e-01   5.95186353e-01   9.33395982e-01   9.55291808e-01\n",
      "   7.52838612e-01   3.81411868e-04   9.49848115e-01   9.89276052e-01\n",
      "   3.96096474e-03   5.50806284e-01]\n",
      "Traning ends. The best valid accuracy is 79.5221843003413. Model named lenet_1513222409.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  9.98891354e-01,   9.27987576e-01,   8.73989344e-01,\n",
       "         6.97654366e-01,   8.51194084e-01,   9.67933178e-01,\n",
       "         9.99927104e-01,   9.97405350e-01,   2.80377833e-04,\n",
       "         8.97766724e-02,   8.51900637e-01,   5.43339908e-01,\n",
       "         9.97880995e-01,   4.14548479e-02,   9.99809206e-01,\n",
       "         5.46674609e-01,   9.99955952e-01,   9.98130977e-01,\n",
       "         5.92833757e-01,   9.99727428e-01,   9.96806741e-01,\n",
       "         9.99961436e-01,   6.96848035e-01,   2.61576060e-04,\n",
       "         6.11735702e-01,   8.12479854e-01,   9.81616318e-01,\n",
       "         4.15899121e-04,   6.87276224e-06,   3.91115900e-03,\n",
       "         9.71560180e-01,   3.31863314e-02,   5.80844343e-01,\n",
       "         5.95186353e-01,   9.33395982e-01,   9.55291808e-01,\n",
       "         7.52838612e-01,   3.81411868e-04,   9.49848115e-01,\n",
       "         9.89276052e-01,   3.96096474e-03,   5.50806284e-01], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.neuralnets.alexnet7 import my_training\n",
    "tf.reset_default_graph()\n",
    "my_training(X_train, y_train, X_val, y_val, X_test,\n",
    "         conv_featmap=[32, 64], \n",
    "         fc_units=[84],\n",
    "         conv_kernel_size=[5, 5], \n",
    "         pooling_size=[2, 2],\n",
    "         l2_norm=0.01,\n",
    "         seed=2,\n",
    "         learning_rate=1e-2,\n",
    "         epoch=50,\n",
    "         batch_size=128,\n",
    "         verbose=False,\n",
    "         pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our classification result through a 3 layer CNN is 79%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
